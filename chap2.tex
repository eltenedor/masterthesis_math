\chapter{Estimating Fundamental Solutions}
\label{chap:2}

The purpose of this section is to study fundamental solutions of the Stokes resolvent problem and to deduce related estimates which will be crucial for  the next chapters.

Let $\lambda = r \e^{\ii \tau}$ with $0 < r < \infty$ and $-\pi + \theta < \tau < \pi - \theta$ and set $k = \sqrt{r} \e^{\ii(\pi + \tau)/2}$.
Then 
$$k^2 = -\lambda\quad\text{ and }\quad \frac{\theta}{2} < \arg(k) < \pi - \frac{\theta}{2}$$
as
\begin{align*}
  \arg(k) = \frac{\pi + \tau}{2} &> \frac{\pi}{2} + \frac{-\pi + \theta}{2} = \frac{\theta}{2} 
  \intertext{on the one hand and}
  &< \frac{\pi}{2} + \frac{\pi - \theta}{2} = \pi  - \frac{\theta}{2}
\end{align*}
on the other hand.
This gives rise to the following estimate
\begin{align}
  \label{eq:imaginaryPartEstimate}
  \Im(k) > \sin(\theta/2) \sqrt{|\lambda|}.
\end{align}
Indeed, we have $$\Im( k) = \sqrt{r} \sin( \frac{\pi + \tau}{2} ) = \sqrt{|\lambda|} \sin( \frac{\pi + \tau}{2} )\quad\text{and}\quad \frac{\theta}{2} < \frac{\pi + \tau}{2} < \pi - \frac{\theta}{2}$$
which gives for $\tau$ with $\frac{\pi + \tau}{2} \leq \frac{\pi}{2}$ that $\sin(\frac{\pi + \tau}{2}) \geq \sin(\frac{\theta}{2} )$ and for $\tau$ with $\frac{\pi + \tau}{2} > \frac{\pi}{2}$ that $\sin(\frac{\pi + \tau}{2}) > \sin(\pi - \frac{\theta}{2} ) = \sin(\frac{\theta}{2} )$.

Before diving into fundamental solutions of the Stokes resolvent problem, we will first consider a fundamental solution for the (scalar) Helmoltz equation in $\R^d$
$$
-\Delta u + \lambda u = 0.
$$
One fundamental solution with pole at the origin is given by
\begin{align}
  \label{eq:definitionFundamentalHelmholtz}
  G(x; \lambda) = \frac{\ii}{4 ( 2\pi )^{\frac{d}{2} - 1}} \cdot \frac{1}{|x|^{d - 2}} \cdot (k |x|)^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)} (k|x|),
\end{align}
where $H_{\nu}^{(1)}(z)$ is the Hankel function of the first kind which can be written as
\begin{align}
  \label{eq:integralRepresentationHankel}
  H_\nu^{(1)}(z) = \frac{2^{\nu + 1} \e^{\ii(z - \nu \pi)} z^\nu}{\ii \sqrt{\pi} \Gamma(\nu + \frac{1}{2})} \int_0^\infty \e^{2 z \ii s} s^{\nu - \frac{1}{2}} (1 + s)^{\nu - \frac{1}{2}} \d s.
\end{align}
This formula holds for $\nu > -\frac{1}{2}$ and $0 < \arg(z) < \pi$.
We will usually set 
\begin{align*}
\nu = \frac{d}{2} - 1 \quad\text{and}\quad z = k|x|. 
\end{align*}
Therefore, the formula \eqref{eq:integralRepresentationHankel} will hold for all dimensions $d \geq 2$ and all $x \in \R^d$.
In the case $d = 2$ formula \eqref{eq:definitionFundamentalHelmholtz} simplifies to 
\begin{align}
  \label{eq:2dDefinitionFundamentalHelmholtz}
  G(x;\lambda) = \frac{\ii}{4} H_{0}^{(1)}(k|x|),
\end{align}
in the case $d = 3$ one has an even easier formula, namely
\begin{align}
  \label{eq:3dDefinitionFundamentalHelmholtz}
  G(x; \lambda) = \frac{\e^{\ii k |x|}}{4 \pi |x|}.
\end{align}

Our first estimate is concerned with derivatives of the fundamental solution for the (scalar) Helmholtz equation.

\begin{lem}
  \label{lem:estimateHelmholtzDerivatives}
  Let $\lambda \in \Sigma_\theta$.
  Then
  \begin{align}
    \label{eq:estimateHelmholtzDerivatives}
    |\nabla_x^l G(x; \lambda)| \leq \frac{ C_l \e^{-c \sqrt{|\lambda|} |x|}}{|x|^{d - 2 + l}}
  \end{align}
  for any integer $l \geq 0$ if $d \geq 3$ and for $l \geq 1$ if $d = 2$.
  Here, $c > 0$ depends only on $\theta$ and $C_l$ depends only on $d$, $l$ and $\theta$.
\end{lem}

\begin{proof}
  We start with the case $l = 0$ and $d \geq 3$.
  Let $\Im(z) > 0$ and $\nu - \frac{1}{2} \geq 0$.
  Then \eqref{eq:integralRepresentationHankel} gives
  \begin{align*}
    |H_\nu^{(1)}(z)|
    &\leq C \e^{-\Im(z)} |z|^\nu \int_0^\infty \e^{-2s \Im(z)} s^{\nu - \frac{1}{2}} (1 + s)^{\nu - \frac{1}{2}} \d s.
  \end{align*}
  Since by the substitution rule
  \begin{align*}
    \e^{\frac{-\Im(z)}{2}} \int_0^\infty \e^{-s \Im(z)} s^{\nu - \frac{1}{2}} ( 1 + s )^{\nu - \frac{1}{2}} \d s
    &= \int_0^\infty \e^{-\Im(z) ( s + \frac{1}{2})} s^{\nu - \frac{1}{2}} ( 1 + s )^{\nu - \frac{1}{2}} \d s \\
    &= \int_{\frac{1}{2}}^\infty \e^{-\Im(z) t } (t^2 - \frac{1}{4} ) ^{\nu - \frac{1}{2}} \d t \\
    &\leq \int_0^\infty e^{-\Im(z) t} t^{2\nu - 1} \d t \\
    &= \int_0^\infty e^{-u} (\frac{ u}{\Im(z)} )^{2 \nu - 1} (\Im(z))^{-1} \d u \\
    &= (\Im(z))^{-2 \nu} \int_0^\infty \e^{-u} u^{2 \nu - 1} \d u,
  \end{align*}
  we can estimate
  \begin{align*}
    |z|^\nu |H_\nu^{(1)}(z)| \leq C |z|^{2 \nu} |\Im(z)|^{-2\nu} \e^{-\frac{\Im(z)}{2}},
  \end{align*}
  which for $z = k|x|$ gives
  \begin{align}
    \label{eq:zHEstimate}
    |kx|^\nu |H_\nu^{(1)}(k |x|)| \leq \sin(\theta/2)^{-2\nu} \e^{-\frac{1}{2} \sin(\theta/2) \sqrt{|\lambda|} |x|},
  \end{align}
  where we used \eqref{eq:imaginaryPartEstimate} to estimate
  \begin{align*}
    (|kx|)^{2\nu} \cdot |\Im(k|x|)|^{-2\nu} 
    = |\lambda|^\nu \cdot |\Im(k)|^{-2\nu} 
    \leq \sin(\theta/2)^{-2\nu}.
  \end{align*}
  Using \eqref{eq:definitionFundamentalHelmholtz}, we estimate for $d \geq 3$ setting $\nu = \frac{d}{2} - 1$
  \begin{align*}
    |G(x; \lambda)| 
    \leq C  |x|^{2 - d} e^{-c \sqrt{|\lambda|} |x|}.
  \end{align*}
  This gives the estimate for $l = 0$ and $d \geq 3$.

  Using the relation
  \begin{align*}
    \frac{\d{}}{\d z} \{ z^{-\nu} H_\nu^{(1)}(z) \} = -z^{-\nu} H_{\nu + 1}^{(1)} (z),
  \end{align*}
  we can inductively establish the estimate \eqref{eq:estimateHelmholtzDerivatives} for $l \geq 1$ and $d \geq 2$:
  For $1 \leq j \leq d$, we calculate
  \begin{align*}
    |\nabla_x^{} G(x; \lambda)|
    &\leq C  \cdot \big\{|x|^{1 - d} \cdot (k|x|)^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(k|x|) - |x|^{d - 2} (k|x|)^{\frac{d}{2} - 1} H_{\frac{d}{2}}^{(1)}(k|x|) k\big\} \\
    &\leq C \cdot |x|^{1 - d}\big\{(k|x|)^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(k|x|) -  (k|x|)^{\frac{d}{2}} H_{\frac{d}{2}}^{(1)}(k|x|) \big\},
  \end{align*}
  where the first summand does not arise in the case $d = 2$ due to \eqref{eq:2dDefinitionFundamentalHelmholtz}.
  The terms in the bracket can now be estimated individually by \eqref{eq:zHEstimate}.
  The extension of this proof to orders of differentiation $l \geq 2$ is straightforward using the Leibniz product rule for higher derivatives.
\end{proof}

In the derivation of the next estimates we will use the following useful interior estimate for solutions of Poisson's equation which we write down for further use.

\begin{lem}
  \label{lem:interiorEstimatePoisson}
  Let $w$ be a solution to $\Delta w = f$ in $\BB(x,r)$. Then
  \begin{align}
    \label{eq:interiorEstimatePoisson}
    |\nabla^l w(x)| \leq C r^{-l} \sup_{\BB(x,r)} |w| + C \max_{0 \leq j \leq l - 1} \sup_{\BB(x,r)} r^{j - l + 2} |\nabla^j f|.
  \end{align}
\end{lem}

\begin{proof}
  If $l = 1$, estimate \eqref{eq:interiorEstimatePoisson} is a consequence of the comparison principle and a proof of this fact can be found in Gilbarg and Trudinger \cite[3.4]{gilbarg}.
  We can now use this estimate to inductively deduce the estimates for higher derivatives.
  Note that by a translation and rescaling like
  \begin{align*}
    u_r(x) \coloneqq u(rx) \quad\text{and}\quad f_r(x) \coloneqq r^2 f(rx)
  \end{align*}
  we may assume that $\Delta w = f$ in $\BB(0,1)$ and that it suffices to prove
  \begin{align}
    \label{eq:interiorEstimatePoissonSimple}
    |\nabla^l w(0) | \leq C \sup_{\BB(0,1)} |w| + C \max_{0 \leq j \leq l - 1} \sup_{\BB(0,1)} |\nabla^j f|.
  \end{align}
  for $l > 1$.
  By the Schwartz Theorem we have that if $w$ solves Poisson's equation with right hand side $f$, then $\nabla^l w$ solves Poisson's equation with right hand side $\nabla^l f$.
  We can thus estimate
  \begin{align*}
    |\nabla^l w(0)|
    &\leq C_l \sup_{\BB(0,1/(2^{(l - 1)}))} |\nabla^{l - 1} w| + C_l \sup_{\BB(0,1/(2^{(l-1)}))} |\nabla^{l - 1} f| \\
    &\leq C_l \sup_{\BB(0,1/(2^{(l-2)})} |\nabla^{l - 2} w| + C_l \big\{ \sup_{\BB(0,1)} |\nabla^{l - 2} f| + \sup_{\BB(0,1)} |\nabla^{l - 1} f| \big\} \\
    &\leq \dots \\
    &\leq C_l \; \sup_{\BB(0,1)} |w| + C_l \sum_{j = 0}^{l - 1} \sup_{B(0,1)} |\nabla^j f|
  \end{align*}
  which readily yields the desired estimate.
\end{proof}

We will need the following asymptotic expansions for the function $z^\nu H_\nu^{(1)}(z)$ in $\C \setminus (-\infty, 0]$.
The derivation of these asymptotic expansions is based on asymptotic expansions of the Bessel functions of the first and the second kind and can be found in Tolksdorf \cite[Sec. 4.2]{tolksdorf}.
\begin{align}
  z^{\nu}H_\nu^{(1)}(z) &= \frac{2^\nu \Gamma(\nu)}{\ii \pi} + \frac{\ii}{\pi} z^2 \log(z) + \omega z^2 + O(|z|^4 |\log(z)) \text{ if } d = 4, \label{eq:asymptoticd4}\\
  z^{\nu} H_{\nu}^{(1)}(z) &= \frac{2^\nu \Gamma(\nu)}{\ii\pi} + \frac{2^\nu \Gamma(\nu - 1)}{4 \pi \ii} z^2 + \omega z^3 + O(|z|^4) \text{ if } d = 5, \label{eq:asymptoticd5}\\
  z^\nu H_\nu^{(1)}(z) &= \frac{2^\nu \Gamma(\nu)}{\ii \pi} + \frac{2^\nu \Gamma(\nu - 1)}{4\pi \ii}z^2 + O(|z|^4 |\log z|) \text{ if } d = 6,\label{eq:asymptoticd6} \\
  z^\nu H_\nu^{(1)}(z) &= \frac{2^\nu \Gamma(\nu)}{\ii \pi} + \frac{2^\nu \Gamma(\nu - 1)}{4 \pi \ii} z^2 + O(|z|^4) \text{ if } d \geq 7.\label{eq:asymptoticd7}
\end{align}


We will denote the fundamental solution for $-\Delta = 0$ in $\R^d$ with pole at the origin by
\begin{align*}
  G(x;0) \coloneqq \begin{cases} -\frac{1}{2\pi} \log(|x|), &\quad\text{for } d = 2, \\c_d \frac{1}{|x|^{d - 2}}, &\quad\text{for } d > 2,  \end{cases}
\end{align*}
where
\begin{align*}
  c_d = \frac{1}{(d - 2) \omega_d}, \quad\text{with}\quad \omega_d = \frac{2\pi^{\frac{d}{2}}}{\Gamma(\frac{d}{2})} = |\mathbb{S}^{d - 1}|.
\end{align*}
Since
\begin{align*}
  (d - 2) \omega_d 
  = 2 ( \frac{d}{2} - 1) \frac{2 \pi^{\frac{d}{2}}}{\Gamma(\frac{d}{2})}
  =  2 (\frac{d}{2} - 1) \frac{2 \pi^{\frac{d}{2}}}{\Gamma(\frac{d}{2} - 1)(\frac{d}{2} - 1)}
  = \frac{4 \pi^{\frac{d}{2}}}{\Gamma(\frac{d}{2} - 1)},
\end{align*}
we will also sometimes use
\begin{align*}
  c_d \coloneqq \frac{\Gamma(\frac{d}{2} - 1)}{4 \pi^{\frac{d}{2}}}.
\end{align*}
The leading coefficient of the asymptotic expansions for $d \geq 3$ will be denoted as
\begin{align}
  \label{eq:Defnad}
  a_d \coloneqq \frac{2^{\frac{d}{2} - 1} \Gamma(\frac{d}{2} - 1)}{\ii \pi}.
\end{align}
The coefficients $a_d$ and $c_d$ are related in the following way
\begin{align*}
  c_d 
  %= \frac{\Gamma(\frac{d}{2} - 1) 2^\nu}{\ii \pi} 
  %=\frac{4 (2 \pi)^{\frac{d}{2} - 1}}{\ii} \frac{\Gamma(\frac{d}{2} - 1)}{4 \pi^{\frac{d}{2}}} 
  =\frac{\ii} {4 (2 \pi)^{\frac{d}{2} - 1}}\; a_d .
\end{align*}
This allows us to write for $d \geq 3$
\begin{align}
  \label{eq:HelmholtzLaplaceDifference}
  G(x;\lambda) - G(x; 0) = \frac{i}{4(2\pi)^{\frac{d}{2} - 1}} \cdot \frac{1}{|x|^{d - 2}} \Big\{ (k|x|)^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(k|x|) - a_d \Big\}.
\end{align}

The following lemma helps us to estimate derivatives of \eqref{eq:HelmholtzLaplaceDifference} and the $2$-dimensional counterpart.

\begin{lem}
  \label{lem:HelmholtzLaplaceDifference}
  Let $\lambda \in \Sigma_\theta$.
  Then
  \begin{align}
    \label{eq:HelmholtzLaplaceDifferenceEstimate}
    |\nabla_x^l \{ G(x; \lambda) - G(x; 0) \}| \leq C |\lambda| |x|^{4 - d - l}
  \end{align}
  if $d \geq 5$ and $l \geq 0$, where $C$ depends only on $d$, $l$ and $\theta$.
  If $d = 3$ or $4$, estimate \eqref{eq:HelmholtzLaplaceDifferenceEstimate} holds for $l \geq 1$ and if $d = 2$, the estimate holds for $l \geq 3$.
\end{lem}

\begin{proof}
  \begin{enumerate}[(a)]
    \item In this part we will show that the desired estimates \eqref{eq:HelmholtzLaplaceDifferenceEstimate} and \eqref{eq:HelmholtzLaplaceDifferenceEstimate} hold if we assume that $|\lambda| |x|^2 > \frac{1}{2}$.
    In this case, Lemma \ref{lem:estimateHelmholtzDerivatives} gives
    \begin{align*}
      |\nabla_x^l \{ G(x; \lambda) - G(x; 0) \} |
      \leq C \Big\{ \frac{\e^{-c \sqrt{|\lambda|} |x|}}{|x|^{d - 2 + l}} + \frac{1}{|x|^{d - 2 + l}} \Big\} \leq C \frac{|\lambda|}{|x|^{d - 4 + l}},
    \end{align*}
    where $C$ depends only on $d$, $l$ and $\theta$.
    Therefore, for the remaining proof we will suppose $|\lambda||x|^2 \leq \frac{1}{2}$.
  \item In this step, we show that we can restrict ourselves to proving \eqref{eq:HelmholtzLaplaceDifferenceEstimate} in three cases: (1) $d \geq 5$ and $l = 0$; (2) $d = 3$ or $4$ and $l = 1$; (3) $d = 2$ and $l = 3$.
    
    Suppose \eqref{eq:HelmholtzLaplaceDifferenceEstimate} holds in case (1) and let $l > 1$.
    If we set $ w(x) = G(x;\lambda) - G(x;0) $, we have $\Delta_x w = \lambda G(x; \lambda)$ in $\R^d \setminus \{0\}$.
    For $f = \lambda G(x; \lambda)$ estimate \eqref{eq:interiorEstimatePoisson} now gives
    \begin{align*}
      |\nabla^l w(x) |
      &\leq C r^{-l} \sup_{\BB(x,r)} |w| + C \max_{0 \leq j \leq l - 1} \sup_{\BB(x,r)} r^{j - l + 2} |\nabla^j f| \\
      &\leq C r^{-l} \sup_{y \in \BB(x,r)} |\lambda| |y|^{4 - d} + C \sum_{j = 0}^{l - 1} \sup_{y \in \BB(x,r)} r^{j - l + 2} |\lambda| |y|^{2 - d - j} \\
      &= C r^{-l} |\lambda| |x - r \frac{x}{|x|} |^{4 - d} + C \sum_{j = 0}^{l - 1} r^{j - l + 2} |\lambda| |x - r \frac{x}{|x|} |^{2 - d - j},
    \end{align*}
    for all $0 < r < |x|$, where we used \eqref{eq:HelmholtzLaplaceDifferenceEstimate} with $l = 1$ for the first summand and \eqref{eq:estimateHelmholtzDerivatives} to estimate the second summand.
    Setting $r = \frac{|x|}{2}$ now gives
    \begin{align*}
      |\nabla^l w(x)| 
      &\leq C |\lambda |x|^{-l} |x|^{4 - d} + C \sum_{j = 0}^{l - 1} |x|^{j - l + 2} |\lambda| |x|^{2 - d - j} \\
      &\leq C |\lambda| |x|^{4 - d - l}.
    \end{align*}

    The proof for case (2) is completely analogous if one sets $w(x) = \nabla_x (G(x; \lambda) - G(x; 0))$ and $f(x) = \lambda \nabla_x G(x; \lambda)$.
    Also case (3) is proven in a similar fashion. We will give the proof for the sake of completeness.

    For $w$ and $f$ as in case (2) by \eqref{eq:HelmholtzLaplaceDifferenceEstimate} we get
    \begin{align*}
      |\nabla^l w(x) |
      &\leq C r^{-l} \sup_{\BB(x,r)} |w| + C \max_{0 \leq j \leq l - 1} \sup_{\BB(x,r)} r^{j - l + 2} |\nabla^j f| \\
      &\leq C r^{-l} \sup_{y \in \BB(x,r)} |\lambda| |y|(|\log |\lambda| |y|^2 | + 1 ) + C \sum_{j = 0}^{l - 1} \sup_{y \in \BB(x,r)} r^{j - l + 2} |\lambda| |y|^{- j - 1} \\
      &\leq S_1 + S_2,
      \intertext{wheras}
      S_1 
      &\leq C r^{-l} |\lambda| |x + r \frac{x}{|x|} | ( |\log |\lambda| |x - r \frac{x}{|x|}|^2 | + |\log( |\lambda||x + r \frac{x}{|x|}|^2 )|+ 1) \\
      &\leq C  |\lambda| |x|^{1-l}(|\log( |\lambda| |x|^2)| + 1)
      \intertext{
        if we choose $r = \frac{|x|}{2}$. For $S_2$ we calculate as before, using estimate \eqref{eq:estimateHelmholtzDerivatives}
  }
      S_2
      &\leq C \sum_{j = 0}^{l - 1} C |x|^{j - l + 2} |\lambda| |x|^{-j - 1} \\
      &\leq C |\lambda| |x|^{1 - l}.
    \end{align*}

  \item In this step we prove \eqref{eq:HelmholtzLaplaceDifferenceEstimate} for $d \geq 5$ and $l = 0$. 
    First, note that for the functions
    \begin{align*}
      &g(x) \coloneqq (k|x|)^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(k|x|), \quad g(0) = a_d, \\
      &h(z) \coloneqq z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(z), \quad h(0) = a_d,
    \end{align*}
    the mean value theorem yields the estimate
    \begin{align*}
      |g(x) - g(0)| \leq |x| \sup_{\BB(0,|x|)} |\nabla f(y)| \leq |x| |k| \sup_{\BB(0,|x|)} \frac{\d{}}{\d z} |h(k|x|)|.
    \end{align*}
    Due to \eqref{eq:HelmholtzLaplaceDifference} we estimate
    \begin{align}
      |G(x; \lambda) - G(x; 0) |
      &\leq C |x|^{2 - d} \cdot |k| |x| \max_{\substack{|z| \leq |k| |x| \\ \Im(z) > 0}} \big| \frac{\d{}}{\d z} \big\{ z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}(z) \big\} \big| \nonumber\\
      &= C |x|^{2 - d} \cdot |k| |x| \max_{\substack{|z| \leq |k||x| \\ \Im(z) > 0}} |z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 2}^{(1)}(z) |, \label{eq:HelmholtzLaplaceDifferenceGt5}
    \end{align}
    where for the last equality we used the relation
    \begin{align}
      \frac{\d{}}{\d z} \big\{ z^\nu H_\nu^{(1)}(z) \big\} = z^\nu H_{\nu - 1}^{(1)}(z).
    \end{align}
    Since the asymptotic expansions yield that $|z^{\nu} H_\nu^{(1)}(z)| \leq C_\nu$ for $\nu > 0$ and $|z| \leq 1$ with $\Im(z) > 0$ it follows from \eqref{eq:HelmholtzLaplaceDifferenceGt5} that
    \begin{align*}
      |G(x;\lambda) - G(x; 0)| \leq C |x|^{2 - d} \cdot |k| |x| \cdot |k| |x| \max_{\substack{|z| \leq |k||x| \\ \Im(z) > 0}} |z^{\frac{d}{2} - 2} H_{\frac{d}{2} - 2}^{(1)}(z) |
      \leq C |\lambda| |x|^{4 - d}
    \end{align*}
    
  \item Now we consider the case $d = 4$ and $l = 1$.
    The asymptotic expansion \eqref{eq:asymptoticd4} gives that
    \begin{align}
      \label{eq:mwt4d}
      \Big| \frac{\d{}}{\d z} \bigg\{ \frac{z H_1^{(1)}(z) - a_4}{z^2} \bigg\} \Big| \leq C |z|^{-1}
    \end{align}
    for all $|z| \leq \frac{1}{2}$ with $\Im(z) > 0$.
    Since
    \begin{align*}
      \frac{G(x; \lambda) - G(x; 0)}{\lambda} = - \frac{C (z H_1^{(1)}(z) - a_4)}{z^2},
    \end{align*}
    where $z = k |x|$, it follows from \eqref{eq:mwt4d} and the mean value theorem that
    \begin{align*}
      \Big|\frac{\nabla_x \{ G(x; \lambda) - G(x; 0) \}}{\lambda} \Big|
      \leq C |k| \frac{\d{}}{\d z} \Big( \frac{z H_1^{(1)}(z) - a_4}{z^2} \Big) \Big|_{z = k|x|}
      \leq C |k| |k|^{-1} |x|^{-1}.
    \end{align*}
    Which after rearrangement of the involved terms gives the claim.

  \item For the case $d = 3$ and $l = 1$, equation \eqref{eq:HelmholtzLaplaceDifference} reads
    \begin{align*}
      G(x;\lambda) - G(x; 0) = \frac{\e^{\ii k |x|}}{4\pi |x|} - \frac{c_3}{|x|} = \frac{\e^{\ii k|x|} - 1}{4 \pi |x|}.
    \end{align*}

    Now we calculate
    \begin{align*}
      \frac{\partial}{\partial x_j} \Big\{ \frac{\e^{\ii k|x|} - 1}{|x|} \Big\} 
      &= \frac{\partial}{\partial x_j} \Big\{ \frac{\e^{\ii k |x|} - 1 - \ii k |x|}{|x|} \Big\} 
      = \frac{\partial}{\partial x_j} \Big\{ \sum_{n = 2}^\infty \frac{(\ii k |x|)^n}{n!} \cdot \frac{1}{|x|} \Big\} \\
      &= \sum_{n = 2}^\infty \frac{(\ii k)^n}{n!} (n - 1) \cdot \frac{x_j}{|x|} |x|^{n - 2} 
    \end{align*}
    which in turn implies 
    \begin{align*}
      \Big| \frac{\partial}{\partial x_j} \Big\{ \frac{\e^{\ii k |x|} - 1}{|x|} \Big\} \Big|
      &\leq |\lambda| \sum_{n = 2}^\infty \frac{n - 1}{n!} |k|^{n - 2} |x|^{n - 2} 
      \leq C \, |\lambda|
    \end{align*}
    since $|\lambda||x| < \frac{1}{2}$.

  \item For the last case $d = 2$ and $l = 3$, we will directly calculate the estimate using the asymptotic expansion of $H_0^{(1)}(z)$ with $z = k|x|$:
    \begin{align*}
      H_0^{(1)}(z) 
      &= J_0(z) + \ii Y_0(z) \\
      &= \sum_{l = 0}^\infty \frac{(-1)^l}{(l!)^2 4^l} z^{2l} \big( 1 - \frac{2\ii \log(2)}{\pi} \big) 
      - \frac{2 \ii}{\pi} \sum_{l = 0}^\infty \frac{(-1)^l}{(l!)^2 4^l} \psi(l + 1) \cdot z^{2l} \\
      &\quad + \frac{2\ii}{\pi} \sum_{l = 0}^\infty \frac{(-1)^l}{(l!)^2 4^l} z^{2l} \log(z)
    \end{align*}
    The first complex derivative of $H_0^{(1)}(z)$ reads
    \begin{align*}
      \frac{\d{}}{\d z} H_0^{(1)}(z) = 
    \end{align*}

  \end{enumerate}
\end{proof}

\begin{rem}
  In the situation of Lemma \ref{lem:HelmholtzLaplaceDifference} one can show by considering the asymptotic expansions and if $|\lambda| |x|^2 \leq (1/2)$ that 
  \begin{align*}
    |G(x; \lambda) - G(x; 0) | \leq \begin{cases}
      C \sqrt{|\lambda|} \quad&\text{if } d = 3, \\
      C |\lambda| \{ |\log(|\lambda| |x|^2) | + 1 \} \quad&\text{if } d = 4.
    \end{cases}
  \end{align*}
  Also using the asymptotic expansions it can be shown that if $d = 2$
  \begin{align*}
    |\nabla_x^l \{ G(x; \lambda) - G(x; 0) \} | \leq C |\lambda| |x|^{2 - l} \{ |\log(|\lambda| |x|^2 ) | + 1 \}
  \end{align*}
  for $l \in \{1, 2\}$.  
\end{rem}

We will now analyze fundamental solutions to the \emph{Stokes resolvent problem}
\begin{align}
  \label{eq:stokesResolventProblem}
  \begin{alignedat}{1}
  -\Delta u + \nabla \phi + \lambda u &= 0 \\
  \div u &= 0
  \end{alignedat}
\end{align}
in $\R^d$ with $\lambda \in \Sigma_\theta$.
  The fundamental solutions to the (scalar) Helmholtz equation and the Laplace equation will form the main ingredients for the following matrix of fundamental solutions $(\Gamma(x;\lambda) = (\Gamma_{\alpha\beta}(x;\lambda))_{d \times d}$ with pole at the origin to the Stokes resolvent problem:
  \begin{align}
    \label{eq:fundamentalMatrixStokes}
    \Gamma_{\alpha\beta}(x;\lambda) = G(x; \lambda) \delta_{\alpha\beta} - \frac{1}{\lambda} \frac{\partial^2}{\partial x_\alpha \partial x_\beta} \{ G(x; \lambda) - G(x; 0) \}, \quad \alpha,\beta = 1,\dots,d.
  \end{align}
  Having the formula at sight, the following observations are obvious:
  \begin{align*}
    \Gamma_{\alpha\beta}(x; \lambda) = \Gamma_{\beta\alpha}(x; \lambda), \quad 
    \overline{\Gamma_{\alpha\beta}(x; \lambda)} = \Gamma_{\alpha\beta}(x; \bar\lambda)
    \quad\text{and}\quad
    \Gamma_{\alpha\beta}(x; \lambda) = \Gamma_{\alpha\beta}(-x; \lambda).
  \end{align*}
  For the pressure, we define the vector of fundamental solutions
  \begin{align}
    \label{eq:fundamentalVectorPressure}
      \Phi_\beta(x) = -\frac{\partial}{\partial x_\beta} \{ G(x; 0) \} = \frac{x_\beta}{\omega_d |x|^d}.
  \end{align}
  We note that $\Phi_\beta(x) = \Phi_\beta(-x)$.

  Using the fact that $\Delta_x G(x; \lambda) = \lambda G(x; \lambda)$ in $\R^d \setminus \{0\}$, one can see that on $\R^d \setminus \{0\}$ and for all $1 \leq \beta \leq d$
  \begin{align}
    \label{eq:solutionStokesSystem}
    \begin{cases}
      (-\Delta_x + \lambda) \Gamma_{\alpha\beta}(x;\lambda) + \frac{\partial}{\partial x_\alpha} \{ \Phi_\beta(x) \} &= 0 \quad\text{for } 1 \leq \alpha \leq d, \\
      \frac{\partial}{\partial x_\alpha} \{ \Gamma_{\alpha\beta} (x; \lambda) \} &= 0.
    \end{cases}
  \end{align}
  Note that in the last equation the summation convention was used.

  We now keep up to the spirit of this exhausting section by proving further estimates, this time for the fundamental solutions to the Stokes resolvent problem \eqref{eq:stokesResolventProblem}

\begin{thm}
  \label{thm:fundamentalMatrixEstimate}
  Let $\lambda \in \Sigma_\theta$.
  Then for any $d \geq 3$ and $l \geq 0$
  \begin{align}
    \label{eq:fundamentalMatrixEstimate}
    | \nabla_x^l \Gamma(x; \lambda) | &\leq \frac{C}{(1 + |\lambda||x|^2) |x|^{d - 2 + l}} 
  \end{align}
    where $C$ depends only on $d$, $l$ and $\theta$. For $d = 2$ and $l \geq 1$ the same estimate holds.
\end{thm}

  \begin{proof}
    Let $|\lambda| |x|^2 > \frac{1}{2}$. 
    Then there exist constants $C_a$, $C_b$, $C_c$ such that
    \begin{align*}
      \e^{-c \sqrt{|\lambda|} |x|} ( 1 + |\lambda| |x|^2) &\leq C_a, \\
      1 &\leq \frac{C_b |\lambda| |x|^2}{1 + |\lambda| |x|^2}, \\
      \e^{-c \sqrt{|\lambda|} |x|} &\leq \frac{ C_c |\lambda| |x|^2}{1 + |\lambda| |x|^2},
    \end{align*}
    where $c$ is the constant from Lemma \ref{lem:estimateHelmholtzDerivatives}.
    Using these estimates and Lemma \ref{lem:estimateHelmholtzDerivatives} gives
    \begin{align*}
      |\nabla_x^l \Gamma(x; \lambda) |
      &\leq |\nabla_x^l G(x; \lambda)| + \frac{1}{|\lambda|} |\nabla_x^{l + 2} G(x; \lambda) | + \frac{1}{|\lambda|} |\nabla_x^{l + 2} G(x; 0)| \\
    &\leq\frac{C_l \e^{-c \sqrt{|\lambda|} |x|}}{|x|^{d - 2 + l}} + \frac{1}{|\lambda|} \frac{C_{l + 2} \e^{-\sqrt{|\lambda|} |x|}}{|x|^2 |x|^{d - 2 + l}} + \frac{1}{|\lambda|} \frac{C}{|x|^2 |x|^{d - 2 + l}} \\
    %&\leq \frac{C}{(1 + |\lambda||x|^2)} \frac{1}{|x|^{d - 2 + l}} + \frac{C_{l + 2} |\lambda||x|^2}{(1 + |\lambda||x|^2)} \frac{1}{|\lambda| |x|^2} \frac{1}{|x|^{d - 2 + l}} + \frac{C}{1 + |\lambda||x|^2} \frac{1}{|x|^{d - 2 + l}}
    &\leq \frac{C}{1 + |\lambda| |x|^2}\; \frac{1}{|x|^{d - 2 + l}}.
    \end{align*}
    Now let $|\lambda| |x|^2 \leq \frac{1}{2}$.
    Then by \ref{lem:estimateHelmholtzDerivatives} and \ref{lem:HelmholtzLaplaceDifference} we get
    \begin{align*}
      |\nabla_x^l \Gamma(x; \lambda) |
      &\leq |\nabla_x^l G(x; \lambda) | + \frac{1}{|\lambda|} |\nabla_x^{l + 2} ( G(x; \lambda) - G(x; 0))| \\
      &\leq \frac{C}{|x|^{d - 2 + l}} + \frac{1}{|\lambda|} \cdot C |\lambda| |x|^{4 - d - (l + 2)} \\
      &\leq \frac{C}{|x|^{d - 2 + l}} \frac{(1 + |\lambda| |x|^2)}{(1 + |\lambda| |x|^2)} \\
      &\leq \frac{C}{(1 + |\lambda| |x|^2) |x|^{d - 2 + l}}
    \end{align*}
    which gives the claim.
    %If $d = 2$ the steps are analogous considering the different structure of the estimate \eqref{eq:HelmholtzLaplaceDifferenceEstimate2d}.
  \end{proof}

 %Regarding the structure of the above proof, the derived estimate for the case $d = 2$ seems natural at first sight. 
 %One important difference compared to $d \geq 3$ is that it is not possible to derive an estimate of the form $|\nabla_x^l \Gamma(x; \lambda)| \leq C |x|^{-l}$.

  If $\lambda = 0$, the matrix of fundamental solutions to the Stokes problem in $\R^d$ with pole at the origin is given by $\Gamma(x; 0) = (\Gamma_{\alpha\beta}(x; 0))_{d \times d}$, where
  \begin{align}
    \label{eq:fundamentalSolutionStokes}
    \Gamma_{\alpha\beta}(x; 0) &= \frac{1}{2 \omega_d} \big\{ \frac{\delta_{\alpha\beta}}{(d - 2) |x|^{d - 2}} + \frac{x_{\alpha} x_\beta}{|x|^d} \big\}
    \intertext{if $d \geq 3$ and}
    \label{eq:fundamentalSolutionStokes2d}
    \Gamma_{\alpha\beta}(x; 0) &= \frac{1}{2 \omega_2} \big\{ - \delta_{\alpha\beta} \log(|x|) + \frac{x_\alpha x_\beta}{|x|^2} \big\}  \end{align}
  for $d = 2$.
  Note that the given fundamental solution for the case $d = 2$ differs from the one given by Mitrea and Wright \cite{mitreaWright} by having summands with alternating signs.
  The alternatig sign is necessary for $\Gamma_{\alpha\beta}$ to be divergence free.

  One important technique in the following chapter will be to reduce problems formulated for $\Gamma(x; \lambda)$ to problems formulated in $\Gamma(x; 0)$ and the difference $\Gamma(x; \lambda) - \Gamma(x; 0)$.
  Under this aspect it seems reasonable to study estimates of the difference of fundamental solutions.
  To this end it is helpful to rewrite parts of the fundamental solution.
  Using the fact that for $d \geq 5$ or $d = 3$
  we have
  \begin{align*}
    \frac{\partial^2}{\partial x_\alpha \partial x_\beta} \big( \frac{1}{|x|^{d - 4}} \big)
    = -(d - 4) \frac{\partial}{\partial x_\alpha} \frac{x_\beta}{|x|^{d - 2}}
    = -(d - 4) \frac{\delta_{\alpha\beta}}{|x|^{d - 2}} + \frac{(d - 4)(d - 2) x_\alpha x_\beta}{|x|^d}
  \end{align*}
  This allows us to express
  \begin{align*}
    \frac{x_\alpha x_\beta}{|x|^d} = \frac{\delta_{\alpha \beta}}{(d - 2)|x|^{d - 2}} + \frac{1}{(d - 4)(d - 2)} \frac{\partial^2}{\partial x_\alpha \partial x_\beta} \big( \frac{1}{|x|^{d - 4}} \big)
  \end{align*}
  which considering \eqref{eq:fundamentalSolutionStokes} gives 
  \begin{align}
    \label{eq:fundamentalSolutionStokes35}
    \Gamma_{\alpha\beta}(x; 0) &= G(x; 0)\delta_{\alpha\beta} + \frac{1}{2\omega_d(d - 4)(d - 2)} \frac{\partial^2}{\partial x_\alpha \partial x_\beta} \big( \frac{1}{|x|^{d - 4}} \big).
  \intertext{A similar trick works for $d = 4$.
  Since $\omega_4 = 2 \pi^2$, we have}
    \Gamma_{\alpha \beta}(x; 0)
    &= \frac{1}{2 \omega_4} \frac{1}{|x|^2} \delta_{\alpha\beta} - \frac{1}{8\pi^2} \big( \frac{\delta_{\alpha\beta}}{|x|^2} - \frac{2 x_\alpha x_\beta}{|x|^4} \big) \nonumber\\
    \label{eq:fundamentalSolutionStokes4}
    &= G(x; 0) \delta_{\alpha\beta} - \frac{1}{8\pi^2} \frac{\partial^2}{\partial x_\alpha \partial x_\beta}( \log(|x|))
  \intertext{In the case $d = 2$ this game shows that since
    $$
  \frac{1}{8\pi} \frac{\partial^2}{\partial_\alpha \partial_\beta} (|x|^2 \log(|x|))
  = \frac{\delta_{\alpha\beta}}{4\pi} \log(|x|) + \frac{1}{4\pi} \frac{x_\alpha x_\beta}{|x|^2} + \frac{\delta_{\alpha\beta}}{8\pi},
$$
we can write}
    \label{eq:fundamentalSolutionStokes2}
    \Gamma_{\alpha \beta}(x; 0) &= G(x; 0)\delta_{\alpha\beta} - \frac{\delta_{\alpha\beta}}{8\pi} - \frac{\partial^2}{\partial x_\alpha \partial x_\beta} (|x|^2 \log(|x|))
  \end{align}
  This ends the preparatory step and brings us to the next theorem.
  
  \begin{thm}
    \label{thm:differenceFundamentalSolutionStokes}
    Let $\lambda \in \Sigma_\theta$.
    Suppose that $|\lambda| |x|^2 \leq \frac{1}{2}$.
    Then
    \begin{align}
      |\nabla_x \{ \Gamma(x; \lambda) - \Gamma(x; 0) \} |
      \leq 
      \begin{cases}
        C |\lambda| |x|^{3 - d} &\quad\text{if } d \geq 7 \text{ or } d = 5, \\
        C |\lambda| |x|^{3 - d} | \log(|\lambda| |x|^2) | &\quad\text{if } d = 4 \text{ or } 6, \\
        C \sqrt{|\lambda|} |x|^{-1} &\quad\text{if } d = 3,\\
        C |\lambda| |x| ( |\log(|\lambda| |x|^2)| + 1 ) &\quad\text{if } d = 2,
      \end{cases}
    \end{align}
    where $C$ depends only on $d$ and $\theta$.
  \end{thm}

\begin{proof}
  We will split the proof in several parts.
  We start by considering the cases $d = 3$ and $d \geq 5$.
      Taking into account \eqref{eq:fundamentalSolutionStokes35} we have
      \begin{align*}
        &\Gamma_{\alpha\beta}(x; \lambda) - \Gamma_{\alpha\beta}(x; 0) \\
        &\qquad= \{ G(x; \lambda) - G(x; 0) \}\delta_{\alpha\beta}  \\
        &\qquad\qquad- \frac{1}{\lambda} \frac{\partial^2}{\partial x_\alpha \partial x_\beta} \Big\{ G(x; \lambda) - G(x; 0) + \frac{\lambda}{2 \omega_d (d - 4) (d - 2) |x|^{d - 4}} \Big\}
      \end{align*}
  As the first term can already be estimated via Lemma \ref{lem:HelmholtzLaplaceDifference}, we will only be concerned about the second one.
  If $d = 3$, a direct calculation will yield the desired result:
  We start by noting that $\omega_3 = 4 \pi$ gives
  \begin{align*}
    \frac{\e^{\ii k |x|}}{4\pi |x|} - \frac{1}{4 \pi |x|} - \frac{(\ii k)^2}{2 \omega_3 |x|^{-1}}
    &= \frac{1}{4 \pi |x|} \Big( \e^{\ii k |x|} - 1 - \frac{ (\ii k)^2 |x|^2}{2} \Big)\\
    &= \frac{1}{4 \pi |x|} \Big( \ii k |x| + \sum_{n = 3}^\infty \frac{(\ii k |x| )^n}{n!} \Big) \\
    &= \frac{1}{4\pi} \Big( \ii k + \sum_{n = 3}^\infty \frac{ (\ii k )^n |x|^{n - 1}}{n!} \Big).
  \end{align*}
  Taking the first derivative of this expression we get
  \begin{align*}
    \frac{\partial}{\partial x_\beta} \dots = 
    \frac{x_\beta}{4 \pi} \sum_{n - 3}^\infty \frac{(ik)^n (n - 1) }{n!} |x|^{n - 3}
  \end{align*}
  and differentiating with respect to $x_\alpha$ yields
  \begin{align*}
    \frac{\partial}{\partial x_\alpha} \dots 
    = \frac{\delta_{\alpha\beta}}{4 \pi} \sum_{n - 3}^\infty \frac{(ik)^n (n - 1) }{n!} |x|^{n - 3}
    + \frac{x_\beta x_\alpha}{4\pi} \sum_{n = 4}^\infty \frac{(\ii k)^n (n - 1) (n - 3)}{n!} |x|^{n - 5}.
  \end{align*}
  As we are interested in estimating the gradient of the difference of $\Gamma(x; \lambda)$ and $\Gamma(x; 0)$ we have to consider one additional derivative. This leaves us with
\begin{align*}
    \frac{\partial}{\partial x_\gamma} \dots
    &= \frac{\delta_{\alpha\beta} x_\gamma + \delta_{\beta\gamma} x_\alpha + \delta_{\alpha\gamma} x_\beta}{4\pi} \sum_{k = 4}^\infty \frac{(\ii k)^n (n - 1) (n - 3)}{n!}  |x|^{n - 5} \\
    &\qquad + \frac{x_\beta x_\alpha x_\gamma}{4\pi} \sum_{\substack{n = 4}}^\infty \frac{(\ii k)^n (n - 1) (n - 3) (n - 5)}{n!} |x|^{n - 7}.
\end{align*}
We can now prove the stated estimate
\begin{align*}
  | \frac{1}{\lambda} \frac{\partial^3}{\partial x_\gamma \partial x_\alpha \partial x_\beta} \dots  |
  &\leq \frac{1}{|k|^2\pi}  \sum_{k = 4}^\infty \frac{|k|^n (n - 1) (n - 3)(1 + (n - 5))}{n!} |x|^{n - 4} \\
  &\leq \frac{1}{|k|^2 |x|\pi} |k|^3 \sum_{k = 4}^\infty \frac{(n - 1)(n - 3)(1 + (n - 5))}{n!} |k|^{n - 3} |x|^{n - 3}\\
  &\leq C \frac{1}{|k| |x|}.
\end{align*}
This gives the claim for $d = 3$.
If $d \geq 5$, equation \eqref{eq:HelmholtzLaplaceDifference} gives
\begin{align*}
  &G(x; \lambda)- G(x; 0) + \frac{\lambda}{2 \omega_2 (d - 4) (d - 2) |x|^{d - 4}} \\
  &\qquad= \frac{\ii}{4 (2\pi)^{\frac{d}{2} - 1}} \frac{1}{|x|^{d - 2}} \big\{ z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(z) - a_d - b_d z^2\big\},
\end{align*}
where $z = k|x|$, $a_d$ was calculated in \eqref{eq:Defnad} and $b_d$ is given by
\begin{align*}
 b_d 
 &= \frac{2\ii (2\pi)^{\frac{d}{2} - 1}}{\omega_d (d - 4) (d - 2)}  
 = -\frac{2\ii (2\pi)^{\frac{d}{2} - 1} \Gamma(\frac{d}{2})}{2\pi^{\frac{d}{2}} (d - 2)(d - 4)}
 = \frac{2^{\frac{d}{2} - 1} }{\pi \ii (d - 4)} \frac{\Gamma(\frac{d}{2})}{(d - 2)} \\
 &= \frac{2^{\frac{d}{2} - 1} }{2\pi \ii } \frac{\Gamma(\frac{d}{2} - 1)}{(d - 4)} 
 = \frac{2^{\frac{d}{2} - 1}}{4 \pi \ii } \frac{\Gamma(\frac{d}{2} - 1)}{(\frac{d}{2} - 1 - 1)}
 = \frac{2^{\frac{d}{2} - 1} \Gamma(\frac{d}{2} - 2)}{4 \pi \ii }.
\end{align*}
If $d \geq 7$ this shows that $b_d$ is the second coefficient of the asymptotic expansion \eqref{eq:asymptoticd7} and thus we can estimate
\begin{align}
  \label{eq:estimateDerivativesd7}
  \big| \frac{\mathrm{d}^l}{\d z^l} \Big\{ z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(z) - a_d - b_d z^2 \Big\} \big| \leq C |z|^{4 - l}
\end{align}
for $0 \leq l \leq 3$ and $z \in \C \setminus (-\infty, 0]$.
For better readability we set
\begin{align*}
  g(z) = z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(z) - a_d - b_d z^2
\end{align*}
and consider the function $f(x) = g(k |x|)$ on $\R^d \setminus \{0\}$.
The derivatives of $f$ read
\begin{align*}
  \frac{\partial}{\partial x_\beta} f(x)
  &= (\frac{\d{}}{\d z} g)(k|x|) \frac{k x_\beta}{|x|} \\
  \frac{\partial^2}{\partial x_\alpha \partial x_\beta} f(x)
  &= (\frac{\mathrm{d}^2}{\d z^2} g)(k|x|) \frac{k^2 x_\alpha x_\beta}{|x|^2} + (\frac{\d{}}{\d z}) g(k |x|) k \Big\{ \frac{\delta_{\alpha\beta}}{|x|} - \frac{x_\beta x_\alpha}{|x|^3} \Big\} \\
  \frac{\partial^3}{\partial x_\gamma \partial x_\alpha \partial x_\beta} f(x)
  &= (\frac{\mathrm{d}^3}{\d z^3}g)(k |x|) \frac{k^3 x_\alpha x_\beta x_\gamma}{|x|^3} \\
  &\quad + (\frac{\mathrm{d}^2}{\d z^2}g)(k|x|) 
  k^2 \Big\{ \frac{x_\alpha \delta_{\beta\gamma} + x_\beta \delta_{\alpha\gamma} + x_\gamma \delta_{\alpha\beta}}{|x|^2} 
  - \frac{3 x_\alpha x_\beta x_\gamma}{|x|^4} \Big\} \\
  &\quad + (\frac{\d{}}{\d z}g)(k|x|) k \Big\{-\frac{\delta_{\alpha\beta} x_\gamma}{|x|^3} - \frac{x_\alpha \delta_{\beta\gamma} + x_\beta \delta_{\alpha\gamma}}{|x|^3} + \frac{3 x_\alpha x_\beta x_\gamma}{|x|^5} \Big\}.
\end{align*}
If we now look for estimates on the absolute value of the derivatives, we see that by \eqref{eq:estimateDerivativesd7}
\begin{align*}
% |\nabla_x f(x) | 
% &\leq C |k|^{4 - 1 + 1} |x|^{4 - 1} = C |k|^{4} |x|^{3}\\
% |\nabla_x^2 f(x) | 
% &\leq C \{ |k|^{4 - 2 + 2} |x|^{4 - 2} + |k|^{4 - 1 + 1} |x|^{4 -1 -1} \}  = C |k|^4 |x|^2 \\
% |\nabla^3_x f(x) | 
% &\leq C \{ |k|^{4 - 3 + 3} |x|^{4 - 3} + |k|^{4 - 2 + 2} |x|^{4 - 2 -1} + |k|^{4 - 1 + 1} |x|^{4 - 1 - 2}
  |\nabla_x^l f(x)| \leq C |k|^4 |x|^{4 - l}, \quad 1 \leq l \leq 3,
\end{align*}
where $C$ only depends on $l$.
We can now finally uncover the desired estimate via
\begin{align*}
  &\Big|\frac{1}{\lambda} \nabla_x^3 \Big\{ \frac{\ii}{4 (2\pi)^{\frac{d}{2} - 1}} \frac{1}{|x|^{d - 2}} \big\{ z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(z) - a_d - b_d z^2\big\} \Big\} \Big| \\
  &\quad\leq C \frac{1}{|k|^2} \sum_{l = 0}^3 | \nabla_x^{3 - l}(\frac{1}{|x|^{d - 2}})| | \nabla_x^l f(x) | 
  \leq C \sum_{l = 0}^3 |x|^{-d + 2 - 3 + l} |k|^2 |x|^{4 - l} = C |\lambda| |x|^{3 - d},
\end{align*}
where $C$ is a constant only depending on $d$.
If $d = 6$, this shows that the asymptotic expansion \eqref{eq:asymptoticd6} gives us similar to \eqref{eq:estimateDerivativesd7}
\begin{align}
  \label{eq:estimateDerivativesd6}
  \big| \frac{\mathrm{d}^l}{\d z^l} \Big\{ z^{\frac{d}{2} - 1} H_{\frac{d}{2} - 1}^{(1)}(z) - a_d - b_d z^2 \Big\} \big| \leq C |z|^{4 - l} | \log(z) |,
\end{align}
for $0 \leq l \leq 3$ and $z \in \C \setminus (-\infty, 0]$.
Using as before the expressions for derivatives of $f$, we can estimate
\begin{align*}
  |\nabla_x^l f(x) | \leq C |k|^4 |x|^{4 - l} |\log(|\lambda| |x|^2) |, 
\end{align*}
which by a calculation analogous to the case $d \geq 7$ yields
\begin{align*}
  | \nabla_x \{ \Gamma(x; \lambda) - \Gamma(x; 0) \}| \leq C |\lambda| |x|^{3 - d} | \log(|\lambda| |x|^2) |.
\end{align*}
For $d = 5$ write
\begin{align*}
  &\frac{\partial^2}{\partial x_\alpha \partial x_\beta} \Big\{ G(x; \lambda) - G(x; 0) + \frac{\lambda}{2 \omega_d (d - 4) (d - 2) |x|{d - 4}} \Big\} \\
  &\qquad= \frac{\partial^2}{\partial x_\alpha x_\beta} \Big\{ \frac{\ii}{4(2\pi)^{\frac{3}{2}}} \cdot \frac{1}{|x|^3} \big[ z^{\frac{3}{2}} H_{\frac{3}{2}}^{(1)}(z) - a_5 - b_5 z^2 - w z^3 \big] \Big\},
\end{align*}
where $w\in\C$ can be an any constant if we set $z = k|x|$.
Now, for the appropriate choice of $w \in \C$ the asymptotic expansion \eqref{eq:asymptoticd5} gives the same estimate as \eqref{eq:estimateDerivativesd7} which proves the claim for $d = 5$.

In the case $d = 4$ we use \eqref{eq:fundamentalSolutionStokes4} to reformulate
\begin{align*}
  &\Gamma_{\alpha\beta}(x; \lambda) - \Gamma_{\alpha\beta}(x; 0) \\
  &\quad= \{ G(x; \lambda) - G(x; 0) \}\delta_{\alpha\beta}  
  - \frac{1}{\lambda} \frac{\partial^2}{\partial x_\alpha \partial x_\beta} \Big\{ G(x; \lambda) - G(x; 0) - \frac{\lambda \log(|x|)}{8 \pi^2} \Big\} \\
  &\quad= \{ G(x; \lambda) - G(x; 0) \} \delta_{\alpha\beta} \\
  &\qquad \frac{\ii}{\lambda} \frac{\partial^2}{\partial x_\alpha \partial x_\beta} \Big\{ \frac{1}{8 \pi |x|^2} [ z H_1^{(1)}(z) - a_4 - w z^2 - b_4 z^2 \log(z)] \Big\},
\end{align*}
where $z = k |x|$, $b_4 = \frac{\ii}{\pi}$ and $w \in \C$ is an arbitrary constant. Using the asymptotic expansion \eqref{eq:asymptoticd4} and the appropriate constant $w \in \C$ we get the estimate
\begin{align*}
  \big| \frac{\mathrm{d}^l}{\d z^l} \Big\{ z H_1^{(1)}(z) - a_4 - w z^2 - b_4 z^2 \log(z) \Big\} \big| \leq C |z|^{4 - l} |\log(z)|.
\end{align*}

For $d = 2$ the estimate follows from a direct calculation.
\end{proof}

We can now use the assumption $|\lambda||x|^2 \leq \frac{1}{2}$  to unify the structure of the estimates for $d \geq 2$.
\begin{cor}
  \label{cor:differenceFundamentalSolutionStokes}
  Let $\lambda \in \Sigma_\theta$. Suppose that $|\lambda||x|^2 \leq \frac{1}{2}$.
  Then for all $d \geq 2$
  \begin{align*}
    |\nabla_x\{ \Gamma(x; \lambda) - \Gamma(x; 0)\} | \leq C \sqrt{|\lambda|} |x|^{2 - d},
  \end{align*}
  where $C$ depends only on $d$ and $\theta$.
\end{cor}

\begin{proof}
  We just extend the estimates given in Theorem \ref{thm:differenceFundamentalSolutionStokes}.
  Let $d \geq 7$ or $d = 5$. Since $|\lambda|^{\frac{1}{2}} \leq C{|x|}$ we have
  \begin{align*}
    C |\lambda| |x|^{3 - d} \leq C |\lambda|^{\frac{1}{2}} |x|^{2 - d}.
  \end{align*}
  For $d = 4,6$ we have
  \begin{align*}
    C |\lambda| |x|^{3 - d} | \log(|\lambda||x|^2)|
    = C |\lambda|^{\frac{1}{2}} |x|^{2 - d} \cdot |\lambda|^{\frac{1}{2}} |x| | \log(|\lambda| |x|^2) |
    \leq C |\lambda|^{\frac{1}{2}} |x|^{2 - d},
  \end{align*}
  since $|\lambda|^{\frac{1}{2}} |x| |\log(|\lambda| |x|^2)|$ is bounded for $|\lambda| |x|^2 \leq \frac{1}{2}$.
  For $d = 2$ the same argument applies to the expression $|\lambda|^{\frac{1}{2}} |x| (|\log(|\lambda| |x|^2)| + 1)$.
\end{proof}

